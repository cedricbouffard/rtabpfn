---
title: "Anomaly Detection with TabPFN"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Anomaly Detection with TabPFN}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

## Introduction

The `rtabpfn` package supports unsupervised anomaly detection through
the `tabpfn-extensions` library. This approach uses TabPFN's joint
probability estimation to identify observations that deviate
significantly from the learned data distribution. Anomaly scores
represent the likelihood of each observation - lower scores indicate
more anomalous data points.

## Setup

First, ensure the Python environment is configured with
tabpfn-extensions:

```{r setup, eval=TRUE}
library(rtabpfn)

# Check if unsupervised extension is available
if (!check_unsupervised_available()) {
  stop("Please install tabpfn-extensions: reticulate::py_install('tabpfn-extensions[unsupervised]', pip = TRUE)")
}
```

Load required packages:

```{r}
library(ggplot2)
library(dplyr)
library(tidyr)
```

## Basic Anomaly Detection

Let's use the `mtcars` dataset to detect anomalous vehicles:

```{r train-model, eval=TRUE}
# Load data
data(mtcars)

# Prepare features
X <- mtcars[, c("cyl", "disp", "hp", "wt", "qsec", "am", "gear")]

# Train unsupervised model
model <- tab_pfn_unsupervised(X, n_estimators = 4, device = "auto")

# Calculate anomaly scores
scores <- anomaly_scores(model, X, n_permutations = 10, verbose = TRUE)

head(scores)
```

## Understanding Anomaly Scores

```{r score-summary, eval=TRUE}
# Add scores to original data
mtcars_with_scores <- mtcars %>%
  mutate(
    observation = scores$observation,
    anomaly_score = scores$anomaly_score,
    car_name = rownames(.)
  )

# Summary statistics
summary(mtcars_with_scores$anomaly_score)

# Find most anomalous vehicles
most_anomalous <- mtcars_with_scores %>%
  arrange(anomaly_score) %>%
  head(10)

print(most_anomalous[, c("car_name", "anomaly_score", "mpg", "cyl", "hp", "wt")])
```

## Visualizing Anomaly Scores

### Anomaly Score Distribution

```{r score-distribution, eval=TRUE}
ggplot(mtcars_with_scores, aes(x = anomaly_score)) +
  geom_histogram(bins = 20, fill = "steelblue", color = "white", alpha = 0.7) +
  geom_vline(xintercept = median(mtcars_with_scores$anomaly_score), 
             linetype = "dashed", color = "darkred") +
  labs(title = "Distribution of Anomaly Scores",
       subtitle = "Lower scores indicate more anomalous observations",
       x = "Anomaly Score",
       y = "Frequency") +
  theme_minimal()
```

### Anomaly Scores by Feature

```{r scores-by-feature, eval=TRUE}
# Anomaly score vs MPG
ggplot(mtcars_with_scores, aes(x = mpg, y = anomaly_score)) +
  geom_point(color = "steelblue", size = 3, alpha = 0.7) +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linetype = "dashed") +
  labs(title = "Anomaly Score vs MPG",
       x = "Miles Per Gallon",
       y = "Anomaly Score") +
  theme_minimal()

# Anomaly score vs Horsepower
ggplot(mtcars_with_scores, aes(x = hp, y = anomaly_score)) +
  geom_point(color = "steelblue", size = 3, alpha = 0.7) +
  geom_smooth(method = "loess", se = TRUE, color = "darkred", linetype = "dashed") +
  labs(title = "Anomaly Score vs Horsepower",
       x = "Horsepower",
       y = "Anomaly Score") +
  theme_minimal()
```

### Feature Space with Anomaly Highlighting

```{r feature-space-anomalies, eval=TRUE}
# Identify top 10% most anomalous
threshold <- quantile(mtcars_with_scores$anomaly_score, 0.90)
mtcars_with_scores$is_anomaly <- mtcars_with_scores$anomaly_score >= threshold

ggplot(mtcars_with_scores, aes(x = wt, y = hp)) +
  geom_point(aes(color = is_anomaly), size = 3, alpha = 0.8) +
  geom_text(data = mtcars_with_scores %>% filter(is_anomaly),
            aes(label = car_name), size = 2, hjust = -0.1, vjust = 0.5) +
  scale_color_manual(values = c("FALSE" = "steelblue", "TRUE" = "darkred"),
                     labels = c("FALSE" = "Normal", "TRUE" = "Anomalous")) +
  labs(title = "Feature Space: Weight vs Horsepower",
       subtitle = paste("Top 10% most anomalous highlighted (n =", sum(mtcars_with_scores$is_anomaly), ")"),
       x = "Weight (1000 lbs)",
       y = "Horsepower",
       color = "Classification") +
  theme_minimal() +
  theme(legend.position = "bottom")
```

## Detailed Anomaly Analysis

### Multi-Feature Comparison

```{r multi-feature-comparison, eval=TRUE}
# Compare normal vs anomalous across features
mtcars_with_scores$is_anomaly_10pct <- mtcars_with_scores$anomaly_score >= 
  quantile(mtcars_with_scores$anomaly_score, 0.90)

feature_long <- mtcars_with_scores %>%
  select(is_anomaly_10pct, cyl, disp, hp, wt, qsec) %>%
  pivot_longer(cols = c(cyl, disp, hp, wt, qsec),
               names_to = "feature",
               values_to = "value") %>%
  mutate(
    feature_label = case_when(
      feature == "cyl" ~ "Cylinders",
      feature == "disp" ~ "Displacement (cu.in.)",
      feature == "hp" ~ "Horsepower",
      feature == "wt" ~ "Weight (1000 lbs)",
      feature == "qsec" ~ "1/4 mile time (sec)"
    ),
    type = ifelse(is_anomaly_10pct, "Anomalous", "Normal")
  )

ggplot(feature_long, aes(x = type, y = value, fill = type)) +
  geom_boxplot(alpha = 0.7) +
  facet_wrap(~ feature_label, scales = "free_y") +
  scale_fill_manual(values = c("Normal" = "steelblue", "Anomalous" = "darkred")) +
  labs(title = "Feature Comparison: Normal vs Anomalous Vehicles",
       subtitle = "Top 10% most anomalous vs rest",
       x = "Classification",
       y = "Feature Value",
       fill = "Classification") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "none")
```

### PCA Visualization

```{r pca-visualization, eval=TRUE}
# Perform PCA for 2D visualization
pca_result <- prcomp(mtcars[, c("cyl", "disp", "hp", "wt", "qsec")], 
                     scale. = TRUE)

mtcars_with_scores <- mtcars_with_scores %>%
  mutate(
    PC1 = pca_result$x[, 1],
    PC2 = pca_result$x[, 2]
  )

ggplot(mtcars_with_scores, aes(x = PC1, y = PC2)) +
  geom_point(aes(color = anomaly_score), size = 3, alpha = 0.7) +
  geom_point(data = mtcars_with_scores %>% filter(is_anomaly),
             shape = 21, size = 4, stroke = 2, color = "darkred", fill = NA) +
  scale_color_gradient2(low = "darkgreen", mid = "yellow", high = "darkred",
                        midpoint = median(mtcars_with_scores$anomaly_score)) +
  labs(title = "PCA Projection with Anomaly Highlighting",
       subtitle = "Color = anomaly score | Red circles = top 10% anomalies",
       x = paste0("PC1 (", round(summary(pca_result)$importance[2, 1] * 100, 1), "% variance)"),
       y = paste0("PC2 (", round(summary(pca_result)$importance[2, 2] * 100, 1), "% variance)"),
       color = "Anomaly Score") +
  theme_minimal()
```

## Threshold Selection

### Finding Optimal Threshold

```{r threshold-selection, eval=TRUE}
# Examine different percentiles
thresholds <- c(0.95, 0.90, 0.85, 0.80, 0.75)

threshold_comparison <- data.frame(
  percentile = thresholds,
  threshold_score = sapply(thresholds, function(p) quantile(mtcars_with_scores$anomaly_score, p)),
  n_anomalies = sapply(thresholds, function(p) sum(mtcars_with_scores$anomaly_score >= quantile(mtcars_with_scores$anomaly_score, p)))
)

print(threshold_comparison)

# Plot
ggplot(threshold_comparison, aes(x = percentile * 100, y = n_anomalies)) +
  geom_line(color = "steelblue", linewidth = 1) +
  geom_point(color = "darkred", size = 3) +
  labs(title = "Number of Anomalies by Threshold Percentile",
       x = "Percentile Threshold (%)",
       y = "Number of Anomalies") +
  scale_x_continuous(breaks = thresholds * 100) +
  theme_minimal()
```

### Anomaly Classification with Threshold

```{r anomaly-classification, eval=TRUE}
# Classify as anomaly if score below 10th percentile
threshold_10 <- quantile(mtcars_with_scores$anomaly_score, 0.90)

mtcars_classified <- mtcars_with_scores %>%
  mutate(
    is_anomaly_10pct = anomaly_score >= threshold_10,
    classification = ifelse(is_anomaly_10pct, "Anomaly", "Normal")
  )

# Summary
summary_table <- mtcars_classified %>%
  group_by(classification) %>%
  summarise(
    n = n(),
    mean_mpg = mean(mpg),
    mean_hp = mean(hp),
    mean_wt = mean(wt),
    .groups = "drop"
  )

print(summary_table)

# Visualize
ggplot(mtcars_classified, aes(x = classification, y = mpg)) +
  geom_boxplot(aes(fill = classification), alpha = 0.7) +
  scale_fill_manual(values = c("Normal" = "steelblue", "Anomaly" = "darkred")) +
  labs(title = "MPG Distribution: Normal vs Anomalous",
       x = "Classification",
       y = "Miles Per Gallon",
       fill = "Classification") +
  theme_minimal()
```

## Analyzing Specific Anomalies

### Detailed Inspection

```{r detailed-inspection, eval=TRUE}
# Get top 5 most anomalous cars
top_anomalies <- mtcars_with_scores %>%
  arrange(anomaly_score) %>%
  head(5)

print(top_anomalies[, c("car_name", "anomaly_score", "mpg", "cyl", "disp", "hp", "wt", "qsec", "am", "gear")])

# Compare each anomaly to median values
median_values <- mtcars_with_scores %>%
  summarise(
    median_mpg = median(mpg),
    median_hp = median(hp),
    median_wt = median(wt),
    median_qsec = median(qsec)
  )

cat("\n=== Median Values (Normal) ===\n")
print(median_values)

cat("\n=== Anomaly Deviation from Median ===\n")
anomaly_deviation <- top_anomalies %>%
  select(car_name, mpg, hp, wt, qsec) %>%
  mutate(
    mpg_diff = mpg - median_values$median_mpg,
    hp_diff = hp - median_values$median_hp,
    wt_diff = wt - median_values$median_wt,
    qsec_diff = qsec - median_values$median_qsec
  )

print(anomaly_deviation[, c("car_name", "mpg_diff", "hp_diff", "wt_diff", "qsec_diff")])
```

### Parallel Coordinates Plot

```{r parallel-coordinates, eval=TRUE}
# Prepare data for parallel coordinates
parallel_df <- mtcars_with_scores %>%
  select(observation,is_anomaly_10pct, mpg, hp, wt, qsec, gear) %>%
  mutate(is_anomaly_10pct = ifelse(is_anomaly_10pct, "Anomaly", "Normal")) %>%
  pivot_longer(cols = c(mpg, hp, wt, qsec, gear),
               names_to = "feature",
               values_to = "value") %>%
  mutate(
    feature_label = case_when(
      feature == "mpg" ~ "MPG",
      feature == "hp" ~ "Horsepower",
      feature == "wt" ~ "Weight",
      feature == "qsec" ~ "1/4 mile time",
      feature == "gear" ~ "Gears"
    ),
    # Normalize within features
    value_norm = as.numeric(scale(value))
  )

ggplot(parallel_df, aes(x = feature_label, y = value_norm, color = is_anomaly_10pct, group = observation)) +
  geom_line(alpha = 0.3) +
  stat_summary(fun = mean, geom = "line", linewidth = 2) +
  scale_color_manual(values = c("Normal" = "steelblue", "Anomaly" = "darkred")) +
  labs(title = "Parallel Coordinates: Normal vs Anomalous",
       subtitle = "Thick lines show mean profiles",
       x = "Feature",
       y = "Normalized Value",
       color = "Classification") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## Time-Series Style Anomaly Detection

```{r timeseries-style, eval=TRUE}
# Order by one feature (e.g., weight) to simulate time-series
mtcars_ordered <- mtcars_with_scores %>%
  arrange(wt) %>%
  mutate(order_idx = row_number())

ggplot(mtcars_ordered, aes(x = order_idx, y = anomaly_score)) +
  geom_line(color = "gray70") +
  geom_point(aes(color = is_anomaly), size = 3) +
  geom_hline(yintercept = threshold_10, linetype = "dashed", color = "darkred") +
  scale_color_manual(values = c("FALSE" = "steelblue", "TRUE" = "darkred")) +
  labs(title = "Anomaly Scores by Vehicle Weight Order",
       subtitle = "Dashed line = 10th percentile threshold",
       x = "Order by Weight",
       y = "Anomaly Score",
       color = "Anomaly") +
  theme_minimal()
```

## Using with Prediction

```{r with-prediction, eval=TRUE, message=FALSE, warning=FALSE, fig.width=6, fig.height=5}
# Combine with regression predictions
X_reg <- mtcars[, c("cyl", "disp", "hp", "wt", "qsec")]
y_reg <- mtcars$mpg

# Train regression model
reg_model <- tab_pfn_regression(X_reg, y_reg, device = "auto")

# Get predictions
reg_preds <- predict(reg_model, X_reg, type = "numeric")

# Combine with anomaly scores
combined_df <- mtcars_with_scores %>%
  select(car_name, anomaly_score, mpg) %>%
  mutate(
    predicted_mpg = reg_preds$.pred,
    prediction_error = abs(mpg - predicted_mpg),
    is_anomaly_10pct = anomaly_score <= threshold_10
  )

# Compare prediction error for normal vs anomalous
error_comparison <- combined_df %>%
  group_by(is_anomaly_10pct) %>%
  summarise(
    n = n(),
    mean_error = mean(prediction_error),
    median_error = median(prediction_error),
    .groups = "drop"
  )

print(error_comparison)

# Plot
ggplot(combined_df, aes(x = is_anomaly_10pct, y = prediction_error)) +
  geom_boxplot(aes(fill = is_anomaly_10pct), alpha = 0.7) +
  scale_fill_manual(values = c("FALSE" = "steelblue", "TRUE" = "darkred"),
                     labels = c("FALSE" = "Normal", "TRUE" = "Anomalous")) +
  labs(title = "Prediction Error: Normal vs Anomalous",
       x = "Classification",
       y = "Absolute Prediction Error (MPG)",
       fill = "Classification") +
  theme_minimal()
```

## Summary

Unsupervised anomaly detection with TabPFN provides:

-   **No labeled data needed**: Detects anomalies based on data
    distribution
-   **Probability-based scoring**: Lower scores indicate more anomalous
    observations
-   **Flexible threshold selection**: Choose appropriate threshold based
    on domain needs
-   **Multi-dimensional detection**: Considers all features
    simultaneously
-   **Interpretable results**: Can analyze which features drive
    anomalous behavior

Key applications: - Data quality monitoring - Fraud detection - System
health monitoring - Novelty detection - Outlier analysis for model
improvement

The method is particularly useful when: - You have unlabeled data - You
need to identify rare or unusual patterns - You want to understand data
distribution anomalies - You're preparing data for supervised learning
